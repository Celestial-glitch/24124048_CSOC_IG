{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8242b1f7-959f-4754-ab4f-ceaa2977c113",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed630456-9875-4daf-9722-f82a40a021a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_recall_curve, auc\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d22a1f-98d2-4df4-b0f4-71cdbba09294",
   "metadata": {},
   "source": [
    "### Loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b870ea9-07f3-46ed-a903-0e72d4d53481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load\n",
    "train_df = pd.read_csv(\"X_train_processed.csv\")\n",
    "test_df = pd.read_csv(\"X_test_processed.csv\")\n",
    "\n",
    "# Split into features and labels\n",
    "X_train = train_df.drop(\"No-show\", axis=1).values\n",
    "y_train = train_df[\"No-show\"].values\n",
    "\n",
    "X_test = test_df.drop(\"No-show\", axis=1).values\n",
    "y_test = test_df[\"No-show\"].values\n",
    "\n",
    "# Convert to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a352f20-ba82-4c88-8511-74e18739d8b8",
   "metadata": {},
   "source": [
    "### Neural network with pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d04d567e-b79f-478a-8c9c-e6f51c032895",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1469a302-dafa-40d2-a685-92fdfa570547",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "model = NeuralNet(input_dim)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c4647-31d4-4178-8e43-ff62cfd00c50",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6836cbfe-ef86-492c-a8a3-8fbccff4f43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6719\n",
      "Epoch 10, Loss: 0.5139\n",
      "Epoch 20, Loss: 0.4798\n",
      "Epoch 30, Loss: 0.4720\n",
      "Epoch 40, Loss: 0.4683\n",
      "Epoch 50, Loss: 0.4658\n",
      "Epoch 60, Loss: 0.4639\n",
      "Epoch 70, Loss: 0.4619\n",
      "Epoch 80, Loss: 0.4600\n",
      "Epoch 90, Loss: 0.4580\n",
      "Epoch 100, Loss: 0.4565\n",
      "Epoch 110, Loss: 0.4553\n",
      "Epoch 120, Loss: 0.4544\n",
      "Epoch 130, Loss: 0.4536\n",
      "Epoch 140, Loss: 0.4530\n",
      "Epoch 150, Loss: 0.4525\n",
      "Epoch 160, Loss: 0.4521\n",
      "Epoch 170, Loss: 0.4517\n",
      "Epoch 180, Loss: 0.4514\n",
      "Epoch 190, Loss: 0.4510\n",
      "Epoch 200, Loss: 0.4505\n",
      "Epoch 210, Loss: 0.4502\n",
      "Epoch 220, Loss: 0.4499\n",
      "Epoch 230, Loss: 0.4496\n",
      "Epoch 240, Loss: 0.4495\n",
      "Epoch 250, Loss: 0.4492\n",
      "Epoch 260, Loss: 0.4490\n",
      "Epoch 270, Loss: 0.4493\n",
      "Epoch 280, Loss: 0.4488\n",
      "Epoch 290, Loss: 0.4486\n",
      "Epoch 300, Loss: 0.4485\n",
      "Epoch 310, Loss: 0.4483\n",
      "Epoch 320, Loss: 0.4482\n",
      "Epoch 330, Loss: 0.4482\n",
      "Epoch 340, Loss: 0.4480\n",
      "Epoch 350, Loss: 0.4482\n",
      "Epoch 360, Loss: 0.4479\n",
      "Epoch 370, Loss: 0.4479\n",
      "Epoch 380, Loss: 0.4478\n",
      "Epoch 390, Loss: 0.4477\n",
      "Epoch 400, Loss: 0.4479\n",
      "Epoch 410, Loss: 0.4477\n",
      "Epoch 420, Loss: 0.4475\n",
      "Epoch 430, Loss: 0.4475\n",
      "Epoch 440, Loss: 0.4475\n",
      "Epoch 450, Loss: 0.4474\n",
      "Epoch 460, Loss: 0.4473\n",
      "Epoch 470, Loss: 0.4473\n",
      "Epoch 480, Loss: 0.4473\n",
      "Epoch 490, Loss: 0.4473\n",
      "Epoch 500, Loss: 0.4471\n",
      "Epoch 510, Loss: 0.4472\n",
      "Epoch 520, Loss: 0.4472\n",
      "Epoch 530, Loss: 0.4471\n",
      "Epoch 540, Loss: 0.4470\n",
      "Epoch 550, Loss: 0.4470\n",
      "Epoch 560, Loss: 0.4470\n",
      "Epoch 570, Loss: 0.4470\n",
      "Epoch 580, Loss: 0.4468\n",
      "Epoch 590, Loss: 0.4469\n",
      "Epoch 600, Loss: 0.4469\n",
      "Epoch 610, Loss: 0.4469\n",
      "Epoch 620, Loss: 0.4469\n",
      "Epoch 630, Loss: 0.4468\n",
      "Epoch 640, Loss: 0.4469\n",
      "Epoch 650, Loss: 0.4467\n",
      "Epoch 660, Loss: 0.4466\n",
      "Epoch 670, Loss: 0.4466\n",
      "Epoch 680, Loss: 0.4466\n",
      "Epoch 690, Loss: 0.4465\n",
      "Epoch 700, Loss: 0.4465\n",
      "Epoch 710, Loss: 0.4465\n",
      "Epoch 720, Loss: 0.4467\n",
      "Epoch 730, Loss: 0.4465\n",
      "Epoch 740, Loss: 0.4463\n",
      "Epoch 750, Loss: 0.4463\n",
      "Epoch 760, Loss: 0.4464\n",
      "Epoch 770, Loss: 0.4464\n",
      "Epoch 780, Loss: 0.4464\n",
      "Epoch 790, Loss: 0.4465\n",
      "Epoch 800, Loss: 0.4463\n",
      "Epoch 810, Loss: 0.4462\n",
      "Epoch 820, Loss: 0.4462\n",
      "Epoch 830, Loss: 0.4463\n",
      "Epoch 840, Loss: 0.4462\n",
      "Epoch 850, Loss: 0.4460\n",
      "Epoch 860, Loss: 0.4464\n",
      "Epoch 870, Loss: 0.4463\n",
      "Epoch 880, Loss: 0.4462\n",
      "Epoch 890, Loss: 0.4461\n",
      "Epoch 900, Loss: 0.4460\n",
      "Epoch 910, Loss: 0.4459\n",
      "Epoch 920, Loss: 0.4459\n",
      "Epoch 930, Loss: 0.4460\n",
      "Epoch 940, Loss: 0.4460\n",
      "Epoch 950, Loss: 0.4458\n",
      "Epoch 960, Loss: 0.4458\n",
      "Epoch 970, Loss: 0.4458\n",
      "Epoch 980, Loss: 0.4458\n",
      "Epoch 990, Loss: 0.4457\n",
      "Training Time: 77.90956377983093\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "losses = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"Training Time:\", training_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84f451-27aa-4eea-9258-e88d0ead2ab0",
   "metadata": {},
   "source": [
    "### test prediction evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af8172e9-202c-414d-aa4c-5fcd103f7fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6018912315627545\n",
      "F1-Score: 0.44101391271202595\n",
      "Confusion Matrix:\n",
      " [[9832 7850]\n",
      " [ 949 3471]]\n",
      "PR-AUC:  0.3535913370487738\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.56      0.69     17682\n",
      "           1       0.31      0.79      0.44      4420\n",
      "\n",
      "    accuracy                           0.60     22102\n",
      "   macro avg       0.61      0.67      0.57     22102\n",
      "weighted avg       0.79      0.60      0.64     22102\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_probs = model(X_test_tensor).numpy().flatten()\n",
    "    predictions = (y_probs > 0.2).astype(int)\n",
    "\n",
    "print(\"Test Accuracy:\", (predictions == y_test).mean())\n",
    "print(\"F1-Score:\", f1_score(y_test, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR-AUC: \", pr_auc)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_kernel",
   "language": "python",
   "name": "torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
